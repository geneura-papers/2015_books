\documentclass[preprint]{elsarticle}
\biboptions{round, numbers}
\usepackage[latin1]{inputenc}
%\usepackage[T1]{fontenc}
%\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{color}
%\usepackage{setspace}
\usepackage{url}
\usepackage[english]{babel}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   TITLE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Applying Computational Intelligence Methods for Predicting the Sales of Newly Published Books in a Real Editorial Business Management Environment: Response to Reviewers\' comments}

\noindent
Dear Sirs,\\

First, we would like to express our gratitude to the Editor in Chief,
the editorial team and the reviewers whose valuable comments on this
paper have significantly improved its quality. All suggestions are
highly appreciated and we have added a line in the acknowledgements
section thanking the reviewers. \\ 

In this new revision, we have carefully addressed all the comments in
the new version of the paper. We will enumerate below these comments
(in italics) and our corresponding response. \\ 

We look forward to hearing from you about the final decision on our paper. \\

\noindent
Yours sincerely,\\
The authors.


%------------------------------------------------------------------------------------
\section{Comments by Reviewer \#1}

\noindent \emph{There are some issues needed to be addressed further:} \\

\noindent (1) \emph{Generally speaking, predicting sales is regarded as a regression problem (numerical output) rather than classification (categorical one). Both CFS and RelieFF are originally designed for classification problem. When CFS is used for regression, please to introduce how to estimate correlations between each feature and output (total sales). Since RReliefF, as a variant of ReliefF, is special for regression, why do not the authors use RReliefF? } 

\begin{verbatim}
In all our experiments we have applied  WEKA's implementation 
of the ReliefF algorithm in the regression problems. 
This version is called "Regressional ReliefF" or "RReliefF" for 
short, which was first introduced and implemented by Robnik-Sikonja 
and Kononenko (in ref. [73] for numeric targets). 
Therefore, we have clarified this point in the text to remove 
any ambiguity.
\end{verbatim}
% Antonio - TODO: say where is this clarification in the text (page/paragraph) 
\begin{verbatim}
For CSF, estimating the correlation between attributes is 
standard linear (Pearson's) correlation. The details have 
been added to the text to clarify this point.
\end{verbatim}
% Antonio - TODO: say where is this clarification in the text (page/paragraph) 


~\\
\noindent (2) \emph{In sub-section 4.2, five methods are introduced, i.e.,M5P,kNN,RF,LR and SVM. In sub-section 5.1, why is MLP (multi-layer perceptron) with one hidden layer described ?} 

\begin{verbatim}
The current paper includes in sub-section 4.2 six methods: M5P, kNN, 
RF, LR, SVM, MLP, and ELM (requested by Reviewer #2). After having 
included ELM, new references have been added (the list of new 
references can be found at the end of this letter).

Moreover, as suggested by Reviewer #2 (see his/her first comment), 
the results obtained with the last two methods have been included and 
analyzed in this new version of the paper.
\end{verbatim}
% Antonio - TODO: say where are these results (table/figure/page)
% where (finally) are we going to put those subsections?   XD

~\\
\noindent (2) \emph{For RF, how many trees are set? }

\begin{verbatim}
As far as the number of trees is concerned, in the experiments 
section, when describing the parameter settings, 
it has been mentioned that the best performance was obtained 
with a number of trees equal to 50.
\end{verbatim}
% Antonio - TODO: say where is this clarification in the text (page/paragraph) 


~\\
\noindent (3) \emph{As we known, tree-based methods (e.g., M5P and RF) themselves embed feature selection procedure. That is, some features are chosen to build trees. It is not fair enough to compare five methods in Table 3. } 

\begin{verbatim}
Although we agree with the reviewer's comment, and the RF and M5P 
have an embedded feature selection mechanism, we believe that it 
is unfair to compare them with the filter based feature selection 
methods we have deployed in our research. 
The aim is simply to show to the decision maker what are the possible 
results when we apply one of the off-the-shelf classifiers available 
in a common open source framework such as WEKA. 
Moreover, it is not uncommon in the literature to see such comparison 
between classifiers, as in the paper:
  M. Fernandez-Delgado, E. Cernadas, S. Barro, and D. Amorim. 2014. 
  Do we need hundreds of classifiers to solve real world 
  classification problems?. J. Mach. Learn. Res. 15, 1, pp.3133-3181
which incorporates a general comparison between all these classifiers.

This has been clarified in the text with the following sentence, at the end of section 5.2 (page XX):

"It is important to note that both RF and M5P have an embedded feature selection mechanism (the variables which compose the final trees), however this is part of their inherent procedure. In the following section we will apply three filter-based feature selection techniques on the dataset, so all the methods will profit."


\end{verbatim}
% Antonio - TODO: Put the number of page.


~\\
\noindent (4) \emph{It seems more reasonable to organize and write that paper according to regression viewpoint only. } 

\begin{verbatim}
The reviewer is right, thus, we have revised the whole paper remarking 
the regression topic present on the work. We have clarified in several
 paragraphs that the problem has been addressed by means of regression 
methods (for instance, note the new title of Section 4.2), or we have 
generally referred to the term `regression' instead of `classification', 
in order to better suit the regression viewpoint.

Moreover this suggestion have been also addressed solving the issue 
related to comment #1, where the application procedure of feature 
selection methods for regression problems has been clarified. 
\end{verbatim}


~\\
\noindent (5) \emph{It is necessary to write that paper more concisely. } 

\begin{verbatim}
Following reviewer's suggestion we have reorganized some parts 
of the text, removed some sentences, and rewritten several paragraphs 
in order to avoid repetition, and also to make them shorter, clearer, 
and easier to comprehend. 

Also, all the tables of results have been moved to the Appendix and 
that data has been presented now as the new Figures XX, YY, ZZ.

Finally, the paper has been completely revised and several 
typographic errors have been fixed. 


We are very grateful the reviewer's valuable suggestions and comments. 
\end{verbatim}
% Antonio - TODO: show some examples of reduced text (page/paragraph), there will be some new figures, I think.
% we have to say: "Paragraph #X in subsection #Y" (naming the paragraphs that we identified and gathered-joined)


~\\

%------------------------------------------------------------------------------------
\section{Comments by Reviewer \#2}

\noindent \emph{This paper applies some machine learning technologies to address issues related to book sales. There are some revisions that should be addressed by authors: } \\


\noindent (1) \emph{The ANN and ELM (extreme learning machine) should be added into the experiments; } 

\begin{verbatim}
Following the reviewer's request, we have conducted several new experiments 
and added the results of ANN (MLP) and ELM to Tables XX, YY, ZZ and
Figures AA, BB accordingly. 
Their results have been also analyzed with the rest of methods, in the 
paragraphs related to each one of the new figures.
A description of both approaches have been also included in subsection 4.2.

In addition new references have been added to the paper, related to these 
methods, namely [REF_XX, REF_YY]. In any case, the list of new references
can be found at the end of this letter.
\end{verbatim}
% Antonio - TODO: Complete with the number of tables and figures, along with the new references


~\\
\noindent (2) \emph{The authors should clarify their main contributions in the introduction parts.}

\begin{verbatim}
Following reviewer's request, we have rewritten the introduction and 
included new paragraphs to better explain the problem and the aim of 
the paper. In addition, we have laid out our methodology to differentiate 
it from other approaches.

We have also remarked the contribution with the paragraphs (see page XX):

"Our intention in this paper is to find out the main factors influencing
sales in order to create a tool that the publisher can use to decide how 
many books should be printed, as well as how to leverage these printed
copies to maximize sales using the decision variables under his
control. That is why, using data obtained from a company that sells
software for publishers, we analyse them and compute predictive models 
that can be mainly used as decision-aid tools for book publishers. With 
these models, publishers will be able to combine their expert knowledge 
about the market with the created forecasting models in order to get a 
reliable estimation of book sales, and, based on it, act consequently 
in order to maximize the books sold for a particular print run. 

This will improve the current decision flow that the publishers follow, 
which consist in analysing (in a subjective way) the quality of the book 
and its features (author, genre, etc), and take a `fuzzy' decision roughly
 between printing 300 copies (standard book) or 5000 (best seller).

This process might be tedious, especially when the amount of data is quite
 large. Moreover, different experts can reach different predictions from 
the same dataset [4].

With these issues in mind, in this paper, we firstly present an 
analysis on a real dataset, provided by the Spanish publishing company 
Trevenque Editorial S.L.
This study has been conducted by means of data mining and visualisation
 techniques. Then, a feature selection process is performed using three
 different methods, in order to find out what are the relevant variables
 describing a book  in the prediction, or estimation, procedure. 
This procedure is performed by applying a set of regression algorithms 
to the different datasets (those with a different number of variables), 
yielding a set of models which could be used as the desired tool. 

Given this, the main contribution of this paper to the state of the art 
is the development of the aforementioned methodology to process book sales 
data, in which: firstly, the most relevant variables are identified, and then,
 these variables are considered to `refine' the data in order to conduct
 accurate predictions on future sales. To our knowledge this is the first 
work in which regression methods have been applied to estimate sales for 
new launched books. Moreover, as stated before, we have used in the study 
a real dataset of book sales (related to the Spanish market), which is 
another point to remark."

\end{verbatim}
% TODO: update with the correct page where those paragraphs can be found


~\\
\noindent (3) \emph{Technologies related to recommend systems may have the ability to deal with this problem. The authors should add the recommend systems into the future work part. } 

\begin{verbatim}
Taking into account the reviewer's comment, the recommendation 
systems have been added to the future work section, at the end 
of Section 7 (see page XX).
\end{verbatim}
% Antonio - TODO: put the correct page when the text is finished


~\\
\noindent (4) \emph{Some tables should be transfer to figures because there are too many tables. } 

\begin{verbatim}
Following reviewer's suggestion, all the results tables have been 
moved to the Appendix and that data has been summarized and 
presented as the new Figures XX, YY, ZZ in order to make that numeric 
data clearer and to improve their comprehension.

Their analysis has been also changed and improved considering Figures 
instead of tables.
\end{verbatim}
% Antonio - TODO: put the correct page when the text is finished


~\\
\noindent (5) \emph{Graphical abstract should be added. This paper is organized well. The authors should revise their work according to above comments. } 

\begin{verbatim}
We agree with the reviewer and have designed (and uploaded) a 
graphical abstract as a visual summary of the paper structure 
and the utility of the obtained results.


We would like to thank this reviewer for his/her suggestions 
and comments to improve the quality of our paper.
\end{verbatim}

~\\


%------------------------------------------------------------------------------------
\section{Comments by Reviewer \#3}

\noindent \emph{There are several concerns should be considered.}\\

\noindent (1) \emph{In section introduction, this manuscript should describe the contribution of this work. } 

\begin{verbatim}
The reviewer is right. The main contribution of this paper to the 
state of the art was not properly described. Thus, as stated above 
in the second response to Reviewer #2, we have clarified this in 
the introduction improving some paragraphs and adding new sentences 
(see page XX):

"Our intention in this paper is to find out the main factors influencing
sales in order to create a tool that the publisher can use to decide how 
many books should be printed, as well as how to leverage these printed
copies to maximize sales using the decision variables under his
control. That is why, using data obtained from a company that sells
software for publishers, we analyse them and compute predictive models 
that can be mainly used as decision-aid tools for book publishers. With 
these models, publishers will be able to combine their expert knowledge 
about the market with the created forecasting models in order to get a 
reliable estimation of book sales, and, based on it, act consequently 
in order to maximize the books sold for a particular print run. 

This will improve the current decision flow that the publishers follow, 
which consist in analysing (in a subjective way) the quality of the book 
and its features (author, genre, etc), and take a `fuzzy' decision roughly
 between printing 300 copies (standard book) or 5000 (best seller).

This process might be tedious, especially when the amount of data is quite
 large. Moreover, different experts can reach different predictions from 
the same dataset [4].

With these issues in mind, in this paper, we firstly present an 
analysis on a real dataset, provided by the Spanish publishing company 
Trevenque Editorial S.L.
This study has been conducted by means of data mining and visualisation
 techniques. Then, a feature selection process is performed using three
 different methods, in order to find out what are the relevant variables
 describing a book  in the prediction, or estimation, procedure. 
This procedure is performed by applying a set of regression algorithms 
to the different datasets (those with a different number of variables), 
yielding a set of models which could be used as the desired tool. 

Given this, the main contribution of this paper to the state of the art 
is the development of the aforementioned methodology to process book sales 
data, in which: firstly, the most relevant variables are identified, and then,
 these variables are considered to `refine' the data in order to conduct
 accurate predictions on future sales. To our knowledge this is the first 
work in which regression methods have been applied to estimate sales for 
new launched books. Moreover, as stated before, we have used in the study 
a real dataset of book sales (related to the Spanish market), which is 
another point to remark."

\end{verbatim}


~\\
\noindent (2) \emph{sections 4.1 and 4.2 should be moved to section 2. } 

\begin{verbatim}
Although the reviewer is right, considering that those sections describe 
methods and metrics used in the state of the art, the authors wanted to 
have section 2 as independent from the rest, given it is a key section on 
every work. 

The authors think that `mixing' background concepts there could mean, 
somehow, a lost in quality for that section.

In addition, we also guess that if those subsections would be moved 
to section 2, maybe section 4.3 should be moved too, as it also describes 
some background concepts (usual evaluation metrics). Thus, the methodology 
section would be certainly quite short.

Finally, the rest of the reviewers haven't requested to change the 
organisation and, moreover, Reviewer #2 has remarked that the paper 
is well organized in his/her last comment.

For these reasons we have decided to maintain those as subsections 
of methodology (section 4).

We hope that the reviewer agrees with this decision.
\end{verbatim}
% Antonio - TODO - check this answer for not doing nothing. XD
% Well, actually I have to undo several things. :(


~\\
\noindent (3) \emph{In section 4, this manuscript should show a flowchart of the proposed forecasting scheme and describe it. } 

\begin{verbatim}
Taking into account the reviewer's comment, we have improved the 
description of the methodology including a flowchart (see Figure XX 
at page YY).

Every step/stage shown in that figure has been described in the 
following paragraphs.
\end{verbatim}


~\\
\noindent (4) \emph{In Section 5, parameter settings of 
M5P, kNN and RF also should be shown. } 

\begin{verbatim}
Reviewer is right, so we have improved Section 5, including the 
parameter settings of M5P, kNN and RF methods (see paragraph XX at 
page YY), along with the configuration parameters for the rest of 
methods.


The authors want to express our gratitude to this reviewer 
for his/her valuable comments and suggestions.
\end{verbatim}
% Antonio - TODO: say paragraph/page where they are.



%------------------------------------------------------------------------------------
\section{New references added after revision}

\begin{verbatim}
[53] G.B. Huang, Q.Y. Zhu, C.K. Siew, Extreme learning machine: 
theory and applications, Neurocomputing 70 (1) (2006) 489-501.

[54] G. Huang, G.B. Huang, S. Song, K. You, Trends in extreme 
learning machines: a review, Neural Networks 61 (2015) 32-48.

[60] Wikipedia, List of Dewey decimal classes, [Online; accessed 
05-May-2016]. https://en.wikipedia.org/wiki/List_of_Dewey_Decimal_classes

[71] M. A. Hall, Correlation-based feature selection for discrete 
and numeric class machine learning, in: Proceedings of the 
Seventeenth International Conference on Machine Learning, ICML2000, 
Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2000, 
pp. 359-366.
\end{verbatim}

\end{document}

