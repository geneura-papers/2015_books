\documentclass{llncs}
\usepackage{graphics}
\usepackage{amssymb}
\usepackage[dvips]{epsfig}
\usepackage[latin1]{inputenc}

\def\CC{{C\hspace{-.05em}\raisebox{.4ex}{\tiny\bf ++}}~}
\addtolength{\textfloatsep}{-0.5cm}
\addtolength{\intextsep}{-0.5cm}


%%%%%%%%%%%%%%%% Titulo %%%%%%%%%%%%%%%
\title{Predicting sales of newly published books} 

%%%%%%%%%%%%%%%% autores %%%%%%%%%%%%%%%
\author {
P.A. Castillo, A.M. Mora, J.J. Merelo,  et al.
}
\institute{Department of Architecture and Computer Technology. CITIC \\
           University of Granada (Spain) \\
~\\
           e-mail: {\tt pacv@ugr.es}}

\date{} 

\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

%% Many companies must face, as one of the most difficult tasks to
%% accomplish, new product sales estimation, since in many cases no
%% historical data to serve as guide is available. 
%% Moreover, some of them lack the knowledge about forecasting methods
%% and they can only make decisions based on the expert sales
  %% managers. 
% Eliminado esto.
When a new book is published the publishing house faces the problem of
how many books should be printed. Printing too many is the main issue,
since it implies a loss of investment due to inventory excess. That is
why in this paper we are tackling the problem or predicting sales to 
print the right amount of books, doing so even before the book has
reached shelves, which is when printing occurs. 
%Thus, making inaccurate predictions may lead to erroneous decisions that result in excess production that will not be sold, or even to a production deficit.
%That is the publishing roll problem, in which publishing companies must estimate the number of volumes printed, taking care not to print more than they actually end up selling. Thus, an automatic prediction of book sales to estimate the publishing roll would be helpful for publishers.
% In the literature, different methods of sales prediction, mainly for
% the fashion industry are proposed. 
% Esto no pega nada en el abstract - JJ
%In these works, when sales are stable with a clear trend over time, the classical methods are a good choice. 
%However, in the case of new products, such as a new book publishing, classical methods do not work properly.
%In this paper, a rule-based decision method is proposed to address the
%problem of predicting the publishing roll.  
% It's not proposed. It just obtained the best result with WEKA. - JJ 
% Publishing roll? ¿Qué es? - JJ
%[Pedro] en la traducción de términos Antonio propone traducirlo como "print run". Lo pongo así.
In this paper, which works with data on published books for several years in 
Spain, we first apply a data visualization and preprocessing strategy to find
out what are the relevant variables in the prediction of sales, and
then use standard data mining software to predict sales, and from them
deduce print-run, based on those variables. Our work discovers which
are the most relevant variables when predicting sales, and is
eventually able to predict sales with remarkable accuracy. In fact,
this method has been validated by the company that provided the data 
and incorporated in a business intelligence tool for publishing houses,
since the obtained models provide information on the decision process and
does not require human intervention either for the operation or for
interpretation.
\end{abstract}


%********************************************************************************
\section{Introduction}

% A partir de datos históricos de tiradas editoriales se plantea el
% uso de varios modelos para la clasificación y predicción de la
% tirada de nuevos títulos editoriales. 

A company that intends to release a new product has a high risk due to
the complexity of the production and distribution processes. 
% tienes que enmarcar el problema. Se trata de productos culturales
% con soporte físico y con ventas relativamente pequeñas. Libros,
% discos, no sé si alguna cosa más. - JJ
A newly launched product is also new to the company, and sales forecasts can
only be based on the experience of similar products. 
In this scope, having accurate estimates of future sales of the new
product is extremely important \cite{ChingChin2010} so that production
runs do not exceed predicted sales. 
Indeed, several studies have demonstrated that improving sale predictions 
(a reduction of forecasting errors) results in an improvement in the 
production \cite{Bayraktar2008,Fildes2010,Saeed2008,Zhao2002}.

% In this sense, the publishing industry is based on very particular and
% established production process, and publishing a book requires several
% steps, between which the distribution is important and plays an
% important role. The publishing process and individual decisions at each step are very
% important. One of those decisions is the number of copies to print. 
  % ¿Esto que tiene que ver con la frase anterior? - JJ
% Thus, a suitable prediction system for new books should take into
% account many details about how the editorial process works. % y? - JJ

% Implementing a good forecasting tool requires not only a good study of
% the state of the art in this field, but also an accurate knowledge of
% the operations and challenges facing the publishing industry and its
% supply chain. % ¿eso es lo que vamos a hacer? - JJ


In the field of publishing industry, the challenge is to print an
adequate number of copies but not too much, as the unsold volumes will
lead to losses, whereas if the number of printed copies was not
enough, you can always print more. 
Thus, it is extremely important using predictive tools to optimize 
production and improve the publishing company profits or minimize losses \cite{Zhao2001}
by forecasting the sales a new book might achieve. 
An example is the optimization of sales \cite{Mattila2002} by
improving profit margins by selling the whole print-run. %publishing roll.  
% [Pedro] "publishing roll" es como he encontrado "tirada editorial" traducido...
% Antonio propone traducirlo como "print run". Lo pongo así.

However, accurately using a predictive tool is a difficult task as
book sales are influenced by various factors that make
them fluctuate and usually they might be not controllable and
sometimes unknown. 
Some have to do with decisions on purchases, others with freight
traffic, and others with the distribution strategy \cite{Little1998}. 

Thus, it is very important to know the product and the variables that
might affect the sales, and how an expert manager can eventually 
take them into account \cite{Armstrong2001,SThomassey2014}. 
                                % ¿Esto también pasa en la industria de la
                                % moda. ¿Qué vamos a usar de esto? - JJ
                                % [Pedro] esto iba referido a la Industria Editorial.
Their impact is difficult to estimate and it is not constant over time, 
hence the difficulty to adequately identify and measure their influence \cite{DeToni2000}.
In addition, some may have correlations between them. 
However, these correlations can be detected using data analysis methods, 
such as Self-Organizing Maps (SOM) \cite{kohonen1998} 
or stepwise regression analysis (SRA) \cite{Chang2009}. % What do they
                                % do? What are the results?

In this research, the problem of how many books should be printed 
when a new book is published is faced using data provided by the 
Spanish publishing company Trevenque Editorial \footnote{{\tt http://editorial.trevenque.es}}.
The company's expert sales managers analyzed historical data 
and applied their knowledge using external variables to calculate
appropriate predictions, for example, increasing or decreasing the 
sales prediction based on season or sales period.
                        % varias citas - JJ
                        % [Pedro] lo modifico para comentar quienes nos facilitaron los datos
                        %  y que así era como funcionaban hasta ese momento.

%In any case, in general companies usually use a forecasting model and then, an expert applies his knowledge, as the company might require an interpretable and understandable model. 

However, carrying out the analysis and forecasting process as described,
may lead to an imprecise analysis and may not take all the variables into account. 
In addition, the process might be tedious, especially when the amount
of data is large, and even, different experts can reach different
predictions from the same data set \cite{ChingChin2010,Sanders1994}.

For these reasons, the industry requires the best suited forecasting
techniques to be adopted so that, estimating sales task is carried out
properly and in an automatic way. 

With this in mind, in this paper a data visualization and preprocessing strategy 
to find out what are the relevant variables describing a book in the prediction 
of book sales is proposed; then several standard data mining models 
for sales forecasting are evaluated so a publishing company 
can deduce and optimize print-run.

The rest of this paper is structured as follows: next, 
Section \ref{sec:soa} presents a comprehensive review of the
approaches found in the bibliography related to the prediction of
sales from product characteristics. 
Then, Section \ref{sec:problem} describes the 
problem of how many books should be printed when a new book is published, 
        % no es el problema de publicación, es el problema de venta
        % de libros sin publicar. Habrá que buscar un nombre - JJ
        %[Pedro] cierto, lo cambio, aunque me ha quedado un nombre muy largo  :)
 followed by Section \ref{sec:methodology} where the
experimental setup and the methodology considered in the study is
presented.  
Section \ref{sec:experiments} reports and analyzes the obtained results with a 
real data set. Finally, conclusions and future work are presented in Section
\ref{sec:conclusionsAndFutureWork}. 


%********************************************************************************
\section{Sales forecasting. State of the art}
\label{sec:soa}

% [Pedro] no se encuentra gran cosa sobre predicción de ventas de libros
%  por eso quiero comenzar hablando de la aplicación de métodos
%  de predicción en la industria en general, que sí hay bastante bibliografía.

% In the literature several proposals to perform the prediction of sales in different fields can be found. 
In the last years, different analysis and forecasting methods, such as
regression models \cite{Papalexopoulos1990}, neural networks \cite{Yoo1999} 
or fuzzy systems \cite{Mastorocostas2001} 
have been applied in different industry sectors, i.e. electricity
consumption, traffic flow or sales forecasting. % ¿Y qué? Esta frase
                                % no aporta nada. La primera frase
                                % tiene que enmarcar el estado del
                                % arte - JJ

Specifically, using time series prediction methods \cite{Chu2003,Brown1959,Winters1960,Box1969,Papalexopoulos1990} 
is perhaps the most used technique to tackle the sales forecasting problems, 
the efficiency of these techniques depends largely on the field of application 
and the problem data as they require a large amount of data for predicting 
sales of new products are not the most suitable for this task \cite{ChingChin2010}.

This is the new book sales forecasting case, for which no historical data 
to make predictions \cite{ChingChin2010,FaderHardie2005,Madsen2008} is available
and only some descriptive variables relative to the new unpublished-book are available.

Methods used to predict book sales have been generally based on experts' 
experience who analyzed data about sales, and taking into account their knowledge 
in industry experience and their perception about trends, could make decisions
on the companies production (how many books should be printed when a new book is published).
This a complex problem as the predictions are influenced by external variables 
that must be taken into account, such as seasonality, promotions or fashions 
that expert managers might subjectively apply \cite{Lapide1999,ChingChin2010,ChernWSF15}.

  %[pedro] sobre la industria editorial no hay trabajos sobre predicción de ventas.
  % Lo habitual ha sido usar el conocimiento de expertos para realizar predicciones 
  %  o aconsejar acerca de la cantidad de libros a imprimir.
  % Lo más parecido que he encontrado son dos trabajos (uno en realidad) de Moon et al. 
  %  sobre "Use Blog Information As Book Sales Prediction":
  %     Moon2010ICSSSM
  %     Moon2010ICEC
Recently, some works propose \cite{Moon2010ICSSSM,Moon2010ICEC} analyzing 
relationships between on-line information and book sales.
Specifically, authors propose using the number of blog references as an indicator 
of book sales.
Different sales patterns are observed by analyzing data obtained.
In any case, in this research, historical data from published books is used, 
and the proposed methodology can not be usable in the problem of unpublished-books 
sales prediction.

%
% pasar a contar los casos de la predicción de ventas en la 
% industria de la moda (SThomassey2014) y de nuevos productos (ChingChin2010)
%
% Son problemas muy similares, ya que no hay datos históricos de los nuevos productos,
% al igual que no los hay sobre ventas, y en los que además influyen mucho las variables 
% externas (estacionalidad, modas, fama del author, etc).
% Hay que echar mano de productos similares o simplemente de los datos que describen el nuevo producto.
%

Some authors have faced the problem of forecasting sales of new products using 
different data mining methods \cite{Hammond1990,Chang2009,ChingChin2010,Thomassey2012,Xia2012}. 
Thomassey et al \cite{SThomassey2014} propose using a clustering method and 
decision trees for sales forecasting in textile-appared fashion industry, 
a very similar issue to the new book publishing problem.
The same problem was previously faced by Xia et al \cite{Xia2012} using a 
forecasting method based on extreme learning machine with adaptive metrics of inputs.
Complexity of this problem is due to the lack of historical data, short lifetime 
of the large number of items, and due to the influence of variables such as 
promotions, fashions, or economic environment \cite{Thomassey2012,Xia2012,SThomassey2014}.

  %[Pedro] otro caso muy similar es el paper de ChingChin2010 sobre:
  % New tea product
  % New cosmetic product
  % New soft drink product
In \cite{ChingChin2010}, a decision-support system for new product sales 
forecasting is proposed to solve three real-world sales forecasting problems 
involving new tea, cosmetic, and soft drink products taking into account 
quantitative variables. 
In this study, it is assumed that products are classified based on their sales 
pattern so that products in the same class would have similar sales pattern.
However, as the authors state, proposed system can not deal with qualitative 
date related to the products, and even more real-world cases, such as consumer 
electronics and fashion products, should be examined, as these industries 
introduce new products every season. 

  %[Pedro] otro caso a comentar es el paper de Chang2009 sobre: 
  % sales forecasting in printed circuit board industry.
In those cases where historical data is available, classical time series 
forecasting methods can be applied, such as in \cite{Chang2009}, where a hybrid 
model integrating K-mean and fuzzy neural networks to forecast the future sales 
of a printed circuit board is proposed.
A similar method is proposed by Chern et al \cite{Chern2015}, who analyze 
historical data along online reviews, reviewer characteristics and review 
influences to understand how electronic word-of-mouth affects product sales. 
Proposed method is suitable in those sales forecasting problems with abundant 
online reviews and historical data.


Taking into account the kind of problem we address in this paper, 
a new product sales prediction for which no historical data is available,
the classical forecasting methods based on time series are not adequate. 
Thus, in this paper the relevant variables in the prediction of sales are determined
using data visualization tools and then, standard data mining software 
to predict sales is used to deduce print-run.
In addition, since publishers need models to explain obtained predictions, 
black box forecasting methods may not be suitable for this problem, so 
models based on rules are tested as an alternative.



%********************************************************************************
\section{The problem}
\label{sec:problem}

%Sales forecasting in editorial industry is a very complex problem. 
        %hala, vuelta la burra al trigo - JJ
        %[Pedro] ea, lo quito   :)
There are several difficulties inherent to the new book sales forecasting, 
such as dealing with limited data, finding adequate forecasting methods, and 
selecting the best method to use \cite{ChingChin2010}.

The main issue of this paper is to compute forecasting of the sales for 
new unpublished-books, for which no historical data is available.
Thus, this paper faces the new book publishing problem using different 
prediction methods and using as inputs the historical sales data related 
to other yet published books, and some descriptive variables relative to 
the new unpublished-book.

In the case of already published books, available historical data might help 
to generate predictive models.
However, in the case of new books there is no historical data to define patterns, 
and only some descriptive data about the new book is available.
In these cases not any forecasting method can be used\cite{Madsen2008,ChernWSF15}. 

An additional issue is the dificulty to compare our model with classical 
forecasting methods, such as time series prediction methods, since books 
do not have specific sales time series.

Throughout this research we collaborated with the company Trevenque Editorial, %\footnote{{\tt http://editorial.trevenque.es}}, 
a company that provides management systems and services for libraries, publishers 
and distributors.

Trevenque company, whose expert manager advised this research, provided 
the initial data set consisting of 3159 books.
In this data set, descriptive information for each book includes price, 
selling points, matter, publisher, sales, returns, among other information.
Table \ref{tabla:paramsOrig50} shows the original set of parameters describing 
each book.

\begin{table}[!h]
\caption{Parameters describing a book, as provided by the company Trevenque.}
\label{tabla:paramsOrig50}
\begin{center}
\begin{tabular}{|c|c|}
\hline 

\begin{minipage}{2.3in} \begin{verbatim}
REFERENCE
AUTHOR
RETAIL PRICE
MATTER1
MATTER2
MATTER3
EDITORIAL
COLLECTION
BOOKBINDING
PRINT-RUN
TOTAL SALES
MALLS SALES
DELEGATES SALES
REST OF SALES
TOTAL SALES FIRST YEAR
MALL SALES FIRST YEAR
DELEGATES SALES FIRST YEAR
REST OF SALES FIRST YEAR
TOTAL DISTRIBUTED
MALLS DISTRIBUTED
DELEGATES DISTRIBUTED
REST OF DISTRIBUTED
TOTAL DISTRIBUTED FIRST YEAR
MALLS DISTRIBUTED FIRST YEAR
DELEGATES DISTRIBUTED FIRST YEAR
\end{verbatim} \end{minipage}     & 

\begin{minipage}{2.3in} \begin{verbatim}
REST OF DISTRIBUTED FIRST YEAR
REPRINTS
NUMBER OF REPRINTS
TOTAL DEVOLUTIONS
MALLS DEVOLUTIONS
DELEGATES DEVOLUTIONS
REST OF DEVOLUTIONS
TOTAL DEVOLUTIONS FIRT YEAR
MALLS DEVOLUTIONS FIRST YEAR
DELEGATES DEVOLUTIONS FIRST YEAR
REST OF DEVOLUTIONS FIRST YEAR
GIFTS
UNITS DISTRIBUTED IN FIRST EDITION
TOTAL SELLING POINTS
MALLS SELLING POINTS
DELEGATES SELLING POINTS
REST OF SELLING POINTS
TOTAL SELLING POINTS FIRST YEAR
MALLS SELLING POINTS FIRST YEAR
DELEGATES SELLING POINTS FIRST YEAR
REST OF SELLING POINTS FIRST YEAR
WEEKS ON SALE
POSITIVE SALE MARKET
MEDIUM SALE MARKET
NEGATIVE SALE MARKET
\end{verbatim} \end{minipage}    \\

\hline
\end{tabular}
\end{center}
\end{table}

In this prediction problem, several variables related to the own book affect 
the forecasts, such as author, price, matter or publisher.

However, there are other external variables that also affect the sales of 
a new book, such as those related to seasonality, trends or promotions, 
that classical prediction methods can not deal with.
However, an expert can consider them to modify the forecast obtained by 
the automatic method. Even publishing companies tend to define rules or 
indexes to subjectively adjust the results of prediction based on external data.


%********************************************************************************
\section{Methodology}
\label{sec:methodology}

There are several issues inherent to the problem of predicting sales of new 
products: the limitation on the amount of data available, the application of 
different methods and choose the most suitable of them.
In addition, there is no a standard methodology to solve the general problem 
of sales forecasting.
Usually, a preliminary analysis of the data is carried out to eliminate those 
variables that describe the product but do not provide useful information during 
the prediction process.

\begin{figure}[!h] 
\begin{center}
  \epsfig{file=stages.eps,width=7cm}
\caption{\small{Three main stages in this research: data analysis, (2) forecasting 
methods testing, and (3) subjectively adjusting the obtained results.}}
\label{fig:stages}
\end{center}
\end{figure}

Thus, in this study there are three main stages (see Figure \ref{fig:stages} 
for details): 
\begin{itemize}

  \item  First, after the editorial company has provided the raw data, taken 
  directly from its database, a selection variables process is carried out. 
  In this stage, an expert sales manager, using the information obtained 
  analyzing the SOM cluster method results, removes some unrelated variables 
  and selects the best variables to be considered in the forecasted model. 
  This task may help to identify leading indicators to be used by the 
  forecasting methods in order to improve the accuracy of future forecasts.

  \item  Then, several forecasting methods has to be tested. In this stage 
  different forecasting methods are used to obtain sales forecasts from the 
  data provided.

  \item  Finally, in some cases, it is necessary a third stage where experienced 
  managers adjust subjectively the results obtained using the forecasting methods. 
  They might manually adjust the forecasting results taking into account their 
  knowledge in industry experience and their perception about trends.

\end{itemize}

%Finally, although different authors have proposed metrics to determine 
%the accuracy of estimates, most companies use metrics based on the analysis 
%of errors, i.e. MAE or RMSE \cite{ChingChin2010,Madsen2008}.

Finally, in the literature different error measures can be found to report 
the results obtained using the prediction methods \cite{ChingChin2010,Madsen2008}. 
Those error measurements are also called error functions or cost functions. 
%One of the most commonly used is the mean absolute error (see equation \ref{eq:MAE}).
In any case, we recommend using widely accepted standard 
equations\footnote{http://www.gepsoft.com/gxpt4kb/Chapter10/Section3/Introduction.htm} 
in order to compare obtained results with those presented in other research 
papers using other methods.
That is why different standard error measurements (Equations \ref{eq:MAE} to \ref{eq:RRSE}), 
implemented in tools like Weka\footnote{http://wiki.pentaho.com/display/DATAMINING} \cite{Witten2011} 
or R\footnote{https://www.otexts.org/fpp/2/5} \cite{Hyndman2013}, are proposed.

Specifically, in order to compute the forecasting errors of the different methods, 
Mean absolute error (MAE), Root mean squared error (RMSE), Relative absolute 
error (RAE) and Root relative squared error (RRSE) have been selected:

\begin{itemize}
  \item \emph{Mean Absolute Error} (MAE):
        \begin{equation}\label{eq:MAE}
            MAE = \frac{1}{n}\sum_{i=1}^n {\mid p_i - o_i\mid}
        \end{equation}

  \item \emph{Root Mean Squared Error} (RMSE):
        \begin{equation}\label{eq:RMSE}
            RMSE = \sqrt{ \frac{1}{n}\sum_{i=1}^n {(p_i - o_i)}^2 }
        \end{equation}

  \item \emph{Relative absolute error} (RAE):
        \begin{equation}\label{eq:RAE}
            RAE = \frac{ \sum_{i=1}^n {\mid p_i - o_i\mid} }{ \sum_{i=1}^n {\mid p_{i-1} - o_i\mid} }
        \end{equation}

  \item \emph{Root relative squared error} (RRSE):
        \begin{equation}\label{eq:RRSE}
            RRSE = \sqrt{ \frac{ \sum_{i=1}^n {(p_i - o_i)}^2  }{ \sum_{i=1}^n {(p_{i-1} - o_i)}^2 }  }
        \end{equation}
\end{itemize}
where $o_i$ is the individual data $i = {1,...,n}$ and $p_i$ is the obtained prediction.


%-------------------------------------------------
\subsection{Data collection and analysis}

In general, historical data is used to make time series, and from them extracting 
common patterns and obtaining accurate predictions.
However, in the case of new products, such as the issue of new books, past patterns 
is difficult to observe as there is no available historical sales data \cite{ChingChin2010}.

In addition, among the variables describing a new book, some may affect 
predictions (those variables provide information), while others may not be 
necessary and even redundant.

Thus, from the initial set of variables, the SOM \cite{kohonen1998} was applied 
in order to reduce the dimensionality of the input data and to choose an 
appropriate set of variables.

\textbf{FALTA EXPLICAR EN UN PAR DE PÁRRAFOS QUÉ ES EL SOM DE KOHONEN.} 

This method is usually applied to analyze data as similar items tend to be 
mapped close together, while those items dissimilar, are mapped apart.
Also, the SOM graph represents and highlight very clearly those regions (clusters) 
with high training sample concentration and fewer where the samples are scarce.


As stated in Section \ref{sec:problem}, an expert sales manager colaborated in 
this research in the stage of data analysis. Thus, the process was as follows:
\begin{itemize}
  \item First, the expert removed superfluous variables, and dimensionality was 
  reduced from 50 to 43 inputs.
  \item Then, the expert, using his knowledge and the information obtained 
  analyzing the SOM results, removed some inputs, reducing the number of 
  variables describing a book from 43 to 13.
  \item The company asked to include the information about \emph{editorial} 
  and \emph{materia}. Thus, in a new iteration, taking into account the expert's 
  advice and the información obtained analyzing the SOM results, the number of 
  inputs was decreased to 7.
  \item In a third step, several forecasting methods were used on the obtained 
  dataset, and the best was choosen to obtain an accurate predicting model.
  \item Finally, some information about the new book, such as \emph{author}, 
  although not included in the obtained models, was taken into account by 
  the expert sales manager to modify the forecasted results. 
\end{itemize}

  %  
  %  El proceso que seguimos, resumido para el paper, es:
  %  
  %  [43 entradas] en 2013-01 vamos a tomar 
  %  	pb_noneg.csv para obtener pb_ventas.csv (es el pb_ventas.arff)
  %  	y hacer el SOM
  %  
  %  [13 entradas] en 2013-02-08 vamos a tomar 
  %  	controlado_reducido.csv.arff (197 líneas)
  %  	pbenero.csv.arff (5656 líneas)
  %  	y hacer el SOM
  %  
  %  [7 entradas; materia editorial] en 2013-02-25 vamos a tomar
  %  	pbRAWtrn.arff
  %  	pbRAWtst.arff
  %  

More specifically, in a first step, the expert analyzed the 50 input variables 
describing each book to remove those that were suplerfuas.
Table \ref{tabla:params43} shows the set of variables describing a book 
(43 total inputs) that the expert manager determined as non-superfluous or 
non-redundant.

\begin{table}[!h]
\caption{Variables describing a book (43 total inputs), after the expert 
manager analized the original dataset provided by the company Trevenque to 
remove some inputs.}
\label{tabla:params43}
\begin{center}
\begin{tabular}{|c|c|}
\hline 

\begin{minipage}{2.3in} \begin{verbatim}
MALLS SELLING POINTS FIRST YEAR
REST OF SALES FIRST YEAR
NEGATIVE SALE MARKET
MALLS DISTRIBUTED FIRST YEAR
TOTAL DEVOLUTIONS
REPRINTS
MALL SALES FIRST YEAR
TOTAL SELLING POINTS FIRST YEAR
UNITS DISTRIBUTED IN FIRST EDITION
PRINT-RUN
NUMBER OF REPRINTS
MALLS DEVOLUTIONS
REST OF SELLING POINTS FIRST YEAR
REST OF SALES
DELEGATES SELLING POINTS
REST OF DEVOLUTIONS
DELEGATES SELLING POINTS FIRST YEAR
POSITIVE SALE MARKET
REST OF DISTRIBUTED FIRST YEAR
REST OF SELLING POINTS
TOTAL DEVOLUTIONS FIRT YEAR
DELEGATES DEVOLUTIONS
\end{verbatim} \end{minipage}     & 

\begin{minipage}{2.3in} \begin{verbatim}
MALLS SALES
TOTAL DISTRIBUTED FIRST YEAR
TOTAL SELLING POINTS
MALLS DISTRIBUTED
DELEGATES DISTRIBUTED FIRST YEAR
MALLS SELLING POINTS
TOTAL SALES FIRST YEAR
MEDIUM SALE MARKET
WEEKS ON SALE
DELEGATES DISTRIBUTED
AUTHOR
DELEGATES SALES FIRST YEAR
GIFTS
MALLS DEVOLUTIONS FIRST YEAR
DELEGATES SALES
REST OF DISTRIBUTED
DELEGATES DEVOLUTIONS FIRST YEAR
TOTAL DISTRIBUTED
REST OF DEVOLUTIONS FIRST YEAR
RETAIL PRICE
TOTAL SALES (output)
\end{verbatim} \end{minipage}    \\

\hline
\end{tabular}
\end{center}
\end{table}

Then, after analizyng the original dataset using the SOM to select the best 
variables to be considered, and taking into account the knowledge of the company 
experienced manager, 13 inputs were considered. 
Figure \ref{fig:som43} shows the initial analisys of dataset using the total 
of 43 descriptive inputs per book.
Table \ref{tabla:params13} shows the set of variables describing a book after 
the second analisys.
	% esta gráfica no aporta nada, ni la siguiente tampoco. No se puede
	% colocar en un trabajo en revista  cómo ha ido el entrenamiento, sino
	% datos serios de análisis estadístico de las variables. 
	% [Pedro] sí, estoy de acuerdo. Esto va con el ISSUE #6
\begin{figure}[!h] 
\begin{center}
\begin{tabular}{c}
  \epsfig{file=som43vars.eps,width=11cm} \\
  \epsfig{file=som43umatrix.eps,width=5cm}
\end{tabular}
\caption{\small{Initial data analysis, using 43 descriptive variables per book, 
using SOM.}}
	% Cojollos, ¿qué trabajo os cuesta poner esto en inglés directamente? - JJ
	% [Pedro] sí, si estoy de acuerdo... hay días que me "sale" el texto en inglés,
	% pero hay días que soltar la parrafada en español me resulta más fácil    :/
        % Sería más bien exploratory data analysis o data visualization. 
        % Un gráfico no es un análisis. Y pon las cosas cortas en inglés, hombre - JJ
\label{fig:som43}
\end{center}
\end{figure}

\begin{table}[!h]
\caption{Variables that describe every book, 13 in total, after the
  second analysis carried out using the SOM along with the company
  experienced manager % él no hizo el análisis. No cuela con ``along with'' - JJ
to select the best variables to be considered to
  solve the sales forecasting problem.} 
\label{tabla:params13}
\begin{center}
\begin{tabular}{|c|}
\hline 

\begin{minipage}{2.3in} \begin{verbatim}
TOTAL DEVOLUTIONS
REPRINTS
TOTAL SELLING POINTS FIRST YEAR
UNITS DISTRIBUTED IN FIRST EDITION
NUMBER OF REPRINTS
TOTAL DEVOLUTIONS FIRT YEAR
TOTAL DISTRIBUTED FIRST YEAR
TOTAL SELLING POINTS
WEEKS ON SALE
TOTAL DISTRIBUTED
RETAIL PRICE
PRINT-RUN
TOTAL SALES (output)
\end{verbatim} \end{minipage}     \\

\hline
\end{tabular}
\end{center}
\end{table}


Finally, after analizyng the dataset with 13 descriptive inputs per
book, and paying attention to the company experienced manager's
recommendations, 7 inputs were considered; specifically, variables
\emph{EDITORIAL} and \emph{MATTER} were included, while
\emph{TOTAL DEVOLUTIONS, REPRINTS, TOTAL SELLING POINTS FIRST YEAR,
  NUMBER OF REPRINTS, TOTAL DEVOLUTIONS FIRT YEAR, TOTAL DISTRIBUTED FIRST YEAR,
  WEEKS ON SALE, PRINT-RUN} were discarded.  
	% Hay que aportar datos de por qué se hizo esto. ¿Análisis de planos?
	% ¿Análisis de varianza? - jj
	% [Pedro] En cuanto estén los SOM definitivos lo añadimos. Está relacionado con el ISSUE #6
Figure \ref{fig:som13} shows the initial analisys of dataset using the SOM on 
the total of 13 descriptive inputs per book.
This, along with the expert manager knowledge determined the final 7 inputs 
to be considered.
Table \ref{tabla:params7} shows the final set of variables describing a book, 
taking into account the company experienced manager knowledge.

\begin{figure}[!h] 
\begin{center}
\begin{tabular}{c}
  \epsfig{file=som13vars.eps,width=11cm} \\
  \epsfig{file=som13umatrix.eps,width=5cm}
\end{tabular}
\caption{\small{Análisis de los datos iniciales, usando 13 variables
    descriptivas por libro, utilizando el SOM.}}
% describir de forma más precisa: visualización usando UMatrix de... - JJ
% ¡y usar nombres en inglés para las variables! - JJ
%[pedro] es el siguiente arreglo que le haré mañana al paper    ;)
\label{fig:som13}
\end{center}
\end{figure}

\begin{table}[!h]
\caption{Final set of variables describing a book, taking into account the company 
experienced manager knowledge, to be considered to solve the sales forecasting problem.}
\label{tabla:params7}
\begin{center}
\begin{tabular}{|c|}
\hline 

\begin{minipage}{2.3in} \begin{verbatim}
UNITS DISTRIBUTED IN FIRST EDITION
TOTAL SELLING POINTS
TOTAL DISTRIBUTED
RETAIL PRICE
MATTER
EDITORIAL
TOTAL SALES (output)
\end{verbatim} \end{minipage}     \\

\hline
\end{tabular}
\end{center}
\end{table}



%-------------------------------------------------
\subsection{Selecting an appropriate forecasting method}

As previously stated, there are many prediction methods available in the 
literature, each one with a different parameter set that may affect the 
obtained results.

However, as in the case of new books only some descriptive data is available 
(compared to those cases in which historical data on sales of published books 
is available), not all forecasting methods can be used in this specific problem.

Thus, in this research five forecasting methods, based on the literature 
review in the introduction 
\cite{Madsen2008,ChingChin2010,Thomassey2012,Xia2012,SThomassey2014}, have been used. 
Well known forecasting methods implemented in the Weka tool
\cite{Hall2009,Witten2011} have been choosen, as these methods are
widely known, and could be very helpful for practitioners to reproduce
experiments and even to solve similar sales prediction problems using
these methods. % eliminado el pie de página, es mejor usar referencias - JJ

Specifically, following forecasting methods are proposed:
\begin{itemize}

 % weka.classifiers.trees.M5P
 %		http://weka.sourceforge.net/doc.dev/weka/classifiers/trees/M5P.html
 \item \emph{M5 Model trees}: 
A decision tree consists of answer-nodes, that indicate a class, and decision-nodes, 
that contain an attribute name and branches to other sub-decision trees.
Building a decision tree can be done using many algorithms, i.e. ID3 and C4.5 \cite{Quinlan1986}.
However, in order to use this model in regression problems, some authors have 
extended the model using methods such as the M5 model tree \cite{Quinlan1986,Quinlan1992,Wang1997,WittenFrank2000}, 
by combining a conventional decision tree and generating linear regression 
functions at the nodes.

The construction of a model tree is similar to that of classical decision 
trees \cite{Solomatine2004}:
The process breaks the input space of the training data through decision points 
(nodes) to assign a linear model suitable for that sub-area of the input space. 
This process may lead to a complex model tree.

Model tree models can learn and tackle tasks with high dimensionality (up to 
hundreds of attributes) and generate reproducible and comprehensible representations, 
what makes them potentially more successful in the eyes of decision makers.

The final model consists of the collection of linear sub-models that brings the 
required non-linearity in dealing with the regression problem
and both the predicted values at the answer-nodes along with the path from the 
root to that node is given as a result.

 % weka.classifiers.functions.LinearRegression
 %		http://weka.sourceforge.net/doc.dev/weka/classifiers/functions/LinearRegression.html
 \item \emph{Linear Regression}:
 Linear regression \cite{Cohen2003,Yan2009,Rencher2102} method models the 
relationship between a scalar dependent variable (outcome) and several independent 
variables (predictor) over the range of values in the data set. 
In this statistical technique, data is modeled using linear functions to estimate 
unknown model parameters, examining the linear correlations between independent 
and dependent variables.

This method of regression provides an adequate and interpretable description of 
how the input affects the output as it models the dependent variable as a linear 
function of the independent variables. Moreover, the linear relation can be 
solved using the least squares method, that minimizes the error between the 
actual data and the regression line \cite{McClendon2015}.

 % weka.classifiers.functions.SMOreg
 %		http://weka.sourceforge.net/doc.dev/weka/classifiers/functions/SMOreg.html
 \item \emph{Support Vector Machine for Regression (SVM)}:
Support vector machine (SVM) \cite{Cortes1995,Shevade1999} method is based on  
statistical learning theory and has succesfully used in classification and  
regression problems \cite{Cao2003,Jari2008}.

In classification problems the algorithm searchs for an optimal hyperplane 
that separates two classes, maximizing the margin between two classes. 
In the case of regression the algorithm chooses a hyperplane close to as many 
of the data points as possible, minimizing the sum of the distances from 
the data points to the hyperplane. 
In both cases, the hyperplane is defined by a subset of training set samples 
(called support vectors).
%This method works well even if the space is highly dimensional and the problem is not linearly separable.

 % weka.classifiers.lazy.IBk 
 %		http://weka.sourceforge.net/doc.dev/weka/classifiers/lazy/IBk.html
 \item \emph{k-Nearest Neighbours (kNN)}: 
The kNN \cite{Aha1991,Mitchell1997} method is an instance-based classifier in 
wich the unknown instances are classified by relating them to the known 
instances using a distance measurement/function (Euclidean, Minkowsky or minimax).

The main idea behind the algorithm is that two instances far enough in the space, 
taking into account the distance function, are less likely to belong to the 
same class than two closely situated instances.

The classification algorithm locates the nearest neighbour in instance space and 
asigns the class of that neighbour to the unknown instance.
In order to improve the robustness of the model, several neighbours can be 
located, assigning the resulting class to an unclassified vector using the 
closest k vectors found in the training set by majority vote.

 % weka.classifiers.functions.MultilayerPerceptron
 %		http://weka.sourceforge.net/doc.dev/weka/classifiers/functions/MultilayerPerceptron.html
 \item \emph{Multilayer Perceptron}:
A Multilayer Perceptron (MLP) \cite{Rosenblatt1962,Widrow1990} is a feedforward 
artificial neural network model that maps the input data onto an appropriate output. 
It is an artificial neural network generally used for classification or 
approximation problems.

This model is a generalization of the standard linear perceptron that uses several 
layers of nodes (called neurons) and that is able to solve linearly inseparable 
problems \cite{SteinwenderBitzer2003}.
Each neuron consists of a linear combination of weighted inputs which is passed 
though a non-linear activation function to produce its output.

This kind of artificial neural network is trained using a supervised learning 
technique called back-propagation.
This training method was developed independly by Werbos \cite{Werbos1974}, 
Parker \cite{Parker1985} and Rumelhart et al. \cite{Rumelhart1985}, and consists
in updating the weights of the output layer neurons once the erroneous output 
has been obtained, and then, propagating the succesive weight layers back to 
the input layer.

A key issue when designing an MLP is the number of hidden layers of neurons.
Lippmann proved in \cite{Lippmann1987} that two hidden layers are enough to 
create classifying regions of any kind. This result was then confirmed in later 
works by Bishop \cite{Bishop1996} and Reed et al. \cite{Reed1999}.

\end{itemize}

The objective is finding the most appropriate forecasting method that minimizes 
the error between the obtained forecast and the actual sales for each new book 
published.


%********************************************************************************
\section{Experiments and Results}
\label{sec:experiments}

Once the methods to be applied have been chosen, they must be applied to data sets 
to obtain the prediction models for each one. 
Later on, the models ability must be validated on non-previously seen data.
Specifically, instead of using the conventional validation strategy based on 
using a training set and later on a testing set (unknown data against which 
the model must be tested), a cross-validation technique \cite{Geisser1993,Kohavi1995,Devijver1982} 
has been used to estimate how accurately the predictive model will perform in 
practice. %, limiting at the same time the overfitting problem.

  %  El proceso que seguimos, resumido para el paper, es:
  %  
  %  [43 entradas] en 2013-01 vamos a tomar 
  %  	pb_noneg.csv para obtener pb_ventas.csv (es el pb_ventas.arff)
  %  
  %  [13 entradas] en 2013-02-08 vamos a tomar 
  %  	controlado_reducido.csv.arff (197 líneas)
  %  	pbenero.csv.arff (5656 líneas)
  %  
  %  [7 entradas; materia editorial] en 2013-02-25 vamos a tomar
  %  	pbRAWtrn.arff
  %  	pbRAWtst.arff

% CONTAR COMO SE HAN PLANIFICADO LAS EJECUCIONES CON LOS DIFERENTES METODOS:
% - se ha usado la implementación de estos 5 métodos del paquete WEKA
% - se han realizado 30 ejecuciones con cada método
% - se ha usado una máquina Linux, Intel(R) Core(TM) i5-4430 CPU at 3.00GHz (4 cores) and 16 GB RAM
% - 

Experiments have been conducted on an Intel(R) Core(TM) i5-4430 CPU at 3.00GHz 
(4 cores) and 16 GB RAM, running Ubuntu Linux 14.04.1 LTS and Java JRE_1.7.0_72.

Proposed methods (M5P, LR, SVM, kNN, MLP) have been selected for this study from 
the Weka implementation, and they were run 30 times with the Weka default parameter 
settings and a different random initialization seed for each run.


Table \ref{tabla:results13} shows obtained results (time to build the model and 
error) after applying the proposed forecasting methods on the dataset with 13 
variables per book.
In this dataset, every book is described using numerical variables, and thus, 
processing the data to build the different models is a fast task despite the 
number of instances.

% Mean absolute error MAE / Root mean squared error RMSE /  Relative absolute error RAE / Root relative squared error RRSE
  % ¿Qué sentido tiene usar los 4 métodos de error? ¿Es que vamos a seleccionar uno? - JJ
  %[pedro] es lo habitual en los trabajos en los que se realizan tareas de predicción
  % en algunos calculan muchos más, pero estos son los más usados. 
\begin{table*}[!h]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline 
 Method 	& Time (sec.) 	      & MAE 		& RMSE 		& RAE (\%) & RRSE (\%) 		\\
\hline
  M5P 		& 2.94 $\pm$ 0.51 	  & 65.49 	& 133.73 	& 11.10 	 & 9.17 	  \\
\hline
  LR 		  & 0.33 $\pm$ 0.07 	  & 100.813 & 257.63 	& 17.09 	 & 17.67 	\\
\hline
  SVM 		& 49.10 $\pm$ 8.05	  & 52.30	  & 139.45	& 8.87     & 9.56  	\\
\hline
  kNN 		& 0.03 $\pm$ 0.01 	  & 198.16 	& 542.93 	& 33.59 	 & 37.24 	\\
\hline
  MLP 		& 12.70 $\pm$ 3.08 	  & 97.18 $\pm$ 24.74 	& 174.77 $\pm$ 31.50 	& 16.47 $\pm$ 4.19 	& 11.99 $\pm$ 2.16 	\\
\hline
\end{tabular}
\end{center}
\caption{\small{Results (errors and time) obtained using the different
    forecasting methods on the dataset with 13 variables per book.}} 
\label{tabla:results13}
\end{table*}


Obtained results (time to build the model and error) using the different 
forecasting methods on the dataset with 7 variables per book can be shown 
in Table \ref{tabla:results7}.
Although in this dataset each book is described using a smaller number of 
variables, two categorical variables, \emph{EDITORIAL} and \emph{MATTER}, are 
included, what that makes harder to process the instances and build the different 
models.

  %[pedro] ya están los resultados de de tabla:results7 para MP5, LR, KNN, SVM.
  % faltan AUN algunas ejecuciones de los de MLP (actualizo con los resultados últimos media+-stdev)
\begin{table*}[!h]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline 
 Method   & Time (sec.)         & MAE     & RMSE    & RAE (\%)  & RRSE (\%)      \\
\hline
  M5P     & 7.77 $\pm$ 1.15     & 117.78  & 260.05  & 18.51     & 17.00  \\
\hline
  LR      & 41.72 $\pm$ 8.41    & 120.29  & 252.91  & 18.91     & 16.54   \\
\hline
  SVM     & 1652.20 $\pm$ 283.50& 109.30  & 251.16   & 17.18    & 16.42   \\
\hline
  kNN     & 0.03 $\pm$ 0.01     & 293.98  & 1071.52  & 46.21    & 70.06   \\
\hline
  MLP     & 3595.24 $\pm$ 97.50 & 691.84 $\pm$ 82.71   & 1619.92 $\pm$ 91.67  & 108.74 $\pm$ 13.00   & 105.91 $\pm$ 5.99   \\
\hline
\end{tabular}
\end{center}
\caption{\small{Results (errors and time) obtained using the different 
forecasting methods on the dataset with 7 variables per book.}}
\label{tabla:results7}
\end{table*}

% - indicar que el uso de las dos variables categóricas hace más difícil de aprender el conjunto
Paying attention to the obtained results shown in tables \ref{tabla:results13} 
and \ref{tabla:results7}, using those categorical variables as part of a big 
data set makes the problem hard to solve, both in required time to build the 
forecasting models as well as in the obtained errors.
However, as stated before, Trevenque expert sales manager, taking into account 
his knowledge in industry experience and their perceptions, decided that 
\emph{EDITORIAL} and \emph{MATTER} should taken into account.


% - indicar pros y contras de los diferentes métodos
% - indicar qué método da mejores resultados
% - indicar qué método es tipo "caja-negra" y cuáles ofrecen modelos "explicables" 

As far as the different methods is concerned, M5P model obtained good results, 
both in time and error, and as stated before, this method can learn and tackle 
tasks with high dimensionality and it generates reproducible and comprehensible 
representations that provide information on the decision process and does not 
require human intervention either for the operation or for interpretation. 
Thus, it is very suitable in order to be incorporated in a publishing company 
processes.

The Linear Regression model outperforms other complex methods, both in time 
(as it is a simple method to train) and in obtained errors.
However, more powerful models, that obtain better results, can be obtained in 
comparable time.

Taking into account the SVM model obtained results, this method obtains the best
errors. Even when used using the default parameter values it exhibit a good 
generalization performance.
However, it is much slower than the others to build the model, not only when 
using the data set with 13 input variables, but when using the data set with 
7 input variables (including \emph{EDITORIAL} and \emph{MATTER}).

kNN is the faster method used in this study, as it is the simpler method.
However, the model is slow when classifying (as there are a large number of 
training examples), and it exhibit a poor generalization ability, as it does not 
learn anything from the training data.

As far as the Multilayer Perceptron, its main drawbacks are both the cost of model 
building (not only parameter and weights setting, but also time to train the 
network) and the fact that it is a back-box model, and thus, it is difficult 
to explain how the forecasts are obtained.
In these experiments, the MLP requires a higher time than other methods, but also
the obtained errors are worse as no parameter tuning to build the models have
been carried out.
Also, the difficulty to process information related to variables \emph{EDITORIAL} 
and \emph{MATTER} might affect the worse results obtained on the final dataset.

%[Pedro] ¿aplicamos tests estadísticos para ver si hay diferencias entre métodos?

Finally, paying attention to the cost in time to obtain the forecasting models 
and their accuracy, the M5P model is the most adequate to solve the problem of 
how many books should be printed when a new book is published.
This forecasting method, as an additional advantage, can be used for products 
with historical sales data and for new products with little or no historical 
data available.


%********************************************************************************
\section{Conclusions and Future Work}
\label{sec:conclusionsAndFutureWork}

In this paper, the problem of how many books should be printed 
when a new book is published is faced using several data-mining and
forecasting methods.

This is a very challenging problem in this industry, because printing a higher 
number of volumnes than those finally sold will lead to losses, 
while printing an adequate number of copies will optimize sales and company earnings.
In addition, there are several difficulties inherent to the new book sales forecasting, 
such as dealing with limited data, finding adequate forecasting methods, and 
selecting the best method to use.

%La investigación descrita en este trabajo se ha llevado a cabo conjuntamente con una empresa editorial que ha facilitado un conjunto de datos con los que trabajar, así como con la ayuda de un experto en ventas de este campo para validar los resultados obtenidos.
A data set consisting of 3159 books provided by the Spanish 
publishing company Trevenque Editorial has been used.

In this paper, a data visualization method has been used to find out what are 
the relevant variables describing a book in the prediction of book sales.
Then, several standard data mining models for sales forecasting have been used 
to forecast new book sales, and from them deduce print-run, based on those 
variables.

The most relevant variables when predicting sales have been determined, 
while unrelated or superfluous ones have been removed, 
and sales predictions have been obtained using five different forecasting 
standard methods.
Not only the obtained forecasting error has been taking into account to evaluate
those methods, but also the the cost of model building as parameter setting and 
the required time to train the model.

In this sense, the decision trees proved to be a suitable model because of the 
ease to explain how the prediction is obtained from the variables that describe 
the new book. 
This, compared to the black-box models such as the artificial neural network 
was decisive from the point of view of the needs of experts and the company.
Moreover, proposed method was validated by the company and incorporated in a 
business intelligence tool for publishing houses.


Overall, this study contributes to the literature by proposing the use of different 
soft-computing standard techniques to solve a new challenging problem.
Moreover, proposed method could be implemented, not only in the editorial 
industry, but also in other domains where the specificity of products is similar, 
and might be of interest to other academic researches and industrial practitioners.


%---------- trabajos futuros

As future work, it would be interesting comparing the obtained forecasting results 
with other methods based on soft-computing, such as genetic programming or fuzzy logic.
Moreover, as default parameters have been used for proposed forecasting methods,
it would be of interest carrying out some parameter tuning procedure in order to
improve obtained results.

Furthermore, since there are some characteristics that may affect product sales 
significantly, another way to improve sales predictions could be making a thorough 
study of the effect of the application of discounts and promotions.


%********************************************************************************
\section*{Acknowledgements}
This work has been supported in part by PreTEL (PRM Consultores - Trevenque),
SIPESCA (Programa Operativo FEDER de Andalucía 2007-2013), TIN2011-28627-C04-02 
and TIN2014-56494-C4-3-P (Spanish Ministry of Economy and Competitivity),
SPIP2014-01437 (Direcci{\'o}n General de Tr{\'a}fico), PRY142/14
(Fundaci{\'o}n P{\'u}blica Andaluza Centro de Estudios Andaluces en la
IX Convocatoria de Proyectos de Investigaci{\'o}n), and PYR-2014-17
GENIL project (CEI-BIOTIC Granada). 
    % ¿Y el contrato con Trevenque?  - JJ
    %[pedro] añadido 

%********************************************************************************
\bibliographystyle{plain}
\bibliography{refs}

\end{document}
